Global:
  name: 'm2m-model'      # Warning: 'debug' and 'test' are reserved name that have a special behavior
  gpus: 1                     # Multi-gpu is not implemented on this branch
Trainer:
  epochs: 500
  seed: 42
  start_eval_epoch: 1
  eval_freq: 1 # set 0 to disable evaluation during training
  clip_grad: null
  ema_decay: 0      # 'Amount of EMA decay, 0 means off. A reasonable value  is 0.999.'
  pretrained_model_path: null #/home/liuxuwei01/PaddleScience-Material/molecule_generation/contrastGT.pdparams # set your pretrained model path here
  cal_metric_during_train: True # True: the metric will be calculated on train dataset
  test_only: null
  check_val_every_n_epochs: 1
  sample_every_val: 1
  val_check_interval: null
  samples_to_generate: 1       # We advise to set it to 2 x batch_size maximum
  samples_to_save: 1
  chains_to_save: 1
  # log_every_steps: 500
  number_chain_steps: 1        # Number of frames in each gif
  final_model_samples_to_generate: 512
  final_model_samples_to_save: 512
  final_model_chains_to_save: 512
  evaluate_all_checkpoints: False
  Optimizer:
    __name__: AdamW
    beta1: 0.9
    beta2: 0.999
    lr: 0.001
Tracker:
  log:
    log_freq: 100 # log frequency [step]
  save:
    output_dir: ./output/DeNMR_CHnmr/CLIP
    save_freq: 100 # set 0 to disable saving during training
    is_save_traj: False
Metric:
  __name__: CSPMetric
  gt_file_path: "./data/mp_20/test.csv"
Model:
  __name__: ContrastiveModel
  graph_encoder:
    pretrained_model_path: "./output/DeNMR_CHnmr/DiffGraphFormer/checkpoints/epoch=438.pdparams" #latest.pdparams
    n_layers_GT: 5
    input_dims:
      X: 17
      E: 5
      y: 525
    hidden_mlp_dims:
      X: 256
      E: 128
      y: 256
    hidden_dims: {'dx': 256, 'de': 64, 'dy': 256, 'n_head': 8, 'dim_ffX': 256, 'dim_ffE': 128, 'dim_ffy': 256}
    output_dims: {'X': 9, 'E': 5, 'y': 0}
    vocab_dim: 256
  nmr_encoder:
    enc_voc_size: 5450
    max_len: 256
    d_model: 256
    ffn_hidden: 1024
    n_head: 8
    n_layers: 3
    drop_prob: 0.0
    projector:
      __name__: Linear
      #pretrained_path: "./output/DeNMR_CHnmr/CLIP/checkpoints/epoch=35.pdparams"
      outfeatures: 512
  diffusion_model: # to be deleted
    extra_features: 'all' # 'all', 'cycles', 'eigenvalues' or null
    conditdim: 512
Dataset:
  train:
    dataset:
      __name__: CHnmrDataset
      path: "./data/CHnmr/train.csv"
      vocab_path: "./data/CHnmr/vocab.src"
      datadir: "./data/CHnmr"
      cache: True
      remove_h: True
    loader:
      num_workers: 0
      use_shared_memory: False
    sampler:
      __name__: DistributedBatchSampler
      shuffle: True
      drop_last: False
      batch_size: 32
  val:
    dataset:
      __name__: CHnmrDataset
      path: "./data/CHnmr/val.csv"
      vocab_path: "./data/CHnmr/vocab.src"
      cache: True
      remove_h: True
    sampler:
      __name__: BatchSampler
      shuffle: True
      drop_last: False
      batch_size: 32
  test:
    dataset:
      __name__: CHnmrDataset
      path: "./data/CHnmr/test.csv"
      vocab_path: "./data/CHnmr/vocab.src"
      cache: True
      remove_h: True
    sampler:
      __name__: BatchSampler
      shuffle: True
      drop_last: False
      batch_size: 32
